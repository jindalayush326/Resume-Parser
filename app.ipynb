{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting PyPDF2\n",
      "  Using cached pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting google.generativeai\n",
      "  Downloading google_generativeai-0.8.3-py3-none-any.whl (160 kB)\n",
      "     -------------------------------------- 160.8/160.8 kB 9.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\ayush jindal\\appdata\\roaming\\python\\python310\\site-packages (from google.generativeai) (2.32.0)\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-5.28.2-cp310-abi3-win_amd64.whl (431 kB)\n",
      "     -------------------------------------- 431.5/431.5 kB 4.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ayush jindal\\appdata\\roaming\\python\\python310\\site-packages (from google.generativeai) (4.12.2)\n",
      "Collecting google-ai-generativelanguage==0.6.10\n",
      "  Downloading google_ai_generativelanguage-0.6.10-py3-none-any.whl (760 kB)\n",
      "     -------------------------------------- 760.0/760.0 kB 6.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\users\\ayush jindal\\appdata\\roaming\\python\\python310\\site-packages (from google.generativeai) (4.66.4)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\ayush jindal\\appdata\\roaming\\python\\python310\\site-packages (from google.generativeai) (2.19.1)\n",
      "Requirement already satisfied: pydantic in c:\\users\\ayush jindal\\appdata\\roaming\\python\\python310\\site-packages (from google.generativeai) (2.8.2)\n",
      "Collecting google-api-python-client\n",
      "  Downloading google_api_python_client-2.149.0-py2.py3-none-any.whl (12.3 MB)\n",
      "     ---------------------------------------- 12.3/12.3 MB 3.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\ayush jindal\\appdata\\roaming\\python\\python310\\site-packages (from google-ai-generativelanguage==0.6.10->google.generativeai) (1.24.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\ayush jindal\\appdata\\roaming\\python\\python310\\site-packages (from google-auth>=2.15.0->google.generativeai) (5.4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\software new\\anaconda\\lib\\site-packages (from google-auth>=2.15.0->google.generativeai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\ayush jindal\\appdata\\roaming\\python\\python310\\site-packages (from google-auth>=2.15.0->google.generativeai) (4.9)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\ayush jindal\\appdata\\roaming\\python\\python310\\site-packages (from google-api-core->google.generativeai) (1.63.2)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in d:\\software new\\anaconda\\lib\\site-packages (from google-api-core->google.generativeai) (2.28.1)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0\n",
      "  Using cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Collecting httplib2<1.dev0,>=0.19.0\n",
      "  Using cached httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Collecting uritemplate<5,>=3.0.1\n",
      "  Using cached uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\ayush jindal\\appdata\\roaming\\python\\python310\\site-packages (from pydantic->google.generativeai) (2.20.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\ayush jindal\\appdata\\roaming\\python\\python310\\site-packages (from pydantic->google.generativeai) (0.7.0)\n",
      "Requirement already satisfied: colorama in d:\\software new\\anaconda\\lib\\site-packages (from tqdm->google.generativeai) (0.4.6)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2\n",
      "  Downloading grpcio_status-1.66.2-py3-none-any.whl (14 kB)\n",
      "Collecting grpcio<2.0dev,>=1.33.2\n",
      "  Downloading grpcio-1.66.2-cp310-cp310-win_amd64.whl (4.3 MB)\n",
      "     ---------------------------------------- 4.3/4.3 MB 4.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in d:\\software new\\anaconda\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google.generativeai) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in d:\\software new\\anaconda\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google.generativeai) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\software new\\anaconda\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in d:\\software new\\anaconda\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\software new\\anaconda\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\software new\\anaconda\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (3.4)\n",
      "Installing collected packages: uritemplate, protobuf, httplib2, grpcio, grpcio-status, google-auth-httplib2, google-api-python-client, google-ai-generativelanguage, google.generativeai\n",
      "Successfully installed google-ai-generativelanguage-0.6.10 google-api-python-client-2.149.0 google-auth-httplib2-0.2.0 google.generativeai-0.8.3 grpcio-1.66.2 grpcio-status-1.66.2 httplib2-0.22.0 protobuf-5.28.2 uritemplate-4.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install google.generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script dotenv.exe is installed in 'C:\\Users\\Ayush Jindal\\AppData\\Roaming\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API KEY Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel(\"models/gemini-1.5-pro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze resume using llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resumes_details(resume):\n",
    "    prompt = f\"\"\"\n",
    "    You are a resume parsing assistant. Extract the following details from the given resume text. Ensure to return \"N/A\" if information is missing or unclear.\n",
    "    \n",
    "    Resume text:\n",
    "    {resume}\n",
    "    \n",
    "    Extract and include the following in a structured JSON format:\n",
    "    1. Full Name\n",
    "    2. Contact Number\n",
    "    3. Email Address\n",
    "    4. Location\n",
    "    5. Skills (separate Technical and Non-Technical Skills)\n",
    "    6. Education (degree, institution, graduation year)\n",
    "    7. Work Experience (company name, role, responsibilities, years of experience)\n",
    "    8. Certifications\n",
    "    9. Languages spoken\n",
    "    \n",
    "    Ensure the output is structured like this:\n",
    "\n",
    "    {{\n",
    "        \"Full Name\": \"...\",\n",
    "        \"Contact Number\": \"...\",\n",
    "        \"Email Address\": \"...\",\n",
    "        \"Location\": \"...\",\n",
    "        \"Skills\": {{\n",
    "            \"Technical Skills\": [...],\n",
    "            \"Non-Technical Skills\": [...]\n",
    "        }},\n",
    "        \"Education\": [\n",
    "            {{\n",
    "                \"Degree\": \"...\",\n",
    "                \"Institution\": \"...\",\n",
    "                \"Years\": \"...\"\n",
    "            }},\n",
    "            ...\n",
    "        ],\n",
    "        \"Work Experience\": [\n",
    "            {{\n",
    "                \"Job Title\": \"...\",\n",
    "                \"Company Name\": \"...\",\n",
    "                \"Years of Experience\": \"...\",\n",
    "                \"Responsibilities\": [\"...\"]\n",
    "            }},\n",
    "            ...\n",
    "        ],\n",
    "        \"Certifications\": [...],\n",
    "        \"Languages spoken\": [...]\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    response = model.generate_content(prompt).text\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload File and extract text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_resume(file_path):\n",
    "    \"\"\"\n",
    "    Function to upload and read a resume PDF file.\n",
    "    \"\"\"\n",
    "    if not file_path.endswith('.pdf'):\n",
    "        return {\"error\": \"The uploaded file is not a PDF.\"}\n",
    "\n",
    "    text = \"\"\n",
    "    reader = PdfReader(file_path)\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_file_path = \"D:\\ml\\project\\Resume Parser/Preeti.pdf\"  \n",
    "resume_text = upload_resume(resume_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining some parameters in regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Name: Preeti\n",
      "Contact Number: +91-7027425855\n",
      "Email Address: Jamdagnipreeti24@gmail.com\n",
      "Location: SECTOR -70, GURUGRAM, HARYANA (122001)\n",
      "Technical Skills: MS-Word, MS-Excel, Power Point, MS Outlook, Savior Attendance Software, Time Office\n",
      "Non-Technical Skills: Training & Development, Competency Matrix Review, Training Need  Identification (TNI), Training Calendar Preparation, Training Record Preparation, Training  Feedback  Analysis, Internal  Training Certificate  Preparation, Skill Development, Skill gap  Analysis, On  Job Training  Plan, Skill  matrix  Upgradation, Auditing (Internal & IATF/ISO/EHS/VSA), Recruitment, Talent  Acquisitions, Candidate sourcing, Candidate screening, Interviewing, Negotiation, Onboarding, Employee  satisfaction  survey, Exit Interviews, Exit Formalities, Exit Analysis, Retention strategies, Compliance Management, Recruitments Audits, MIS Updating, KRA  Updating, R&R  and J.D Preparation, Organization  Chart  preparation, Employee  Engagement  Activities, Team  Building, Workforce  Planning, Hiring, CV screening, Motivation  & Empowerment, Team  Player, Leadership, Energetic, Responsible, Committed to deadline, Environment adaptive\n",
      "Education: MBA from University School of Management, KUK (Graduated: 2022)\n",
      "Graduation from Metis Degree College, C.R.S University (Graduated: 2020)\n",
      "12th / Intermediate from Vivekanand Sr. Secondary School (Graduated: 2017)\n",
      "10th / High School from Govt. High School (Graduated: 2015)\n",
      "Work Experience: Executive at ASK Auto motive Ltd. (1 Year, 6 Months)\n",
      "Responsibilities: White - & Blue -Collar  Training &  Development, Training  Procedure  Review, Competency  Matrix Review  – White  Collar, Training  Need  Identification (TNI), Training  Calendar  Preparation  (Annual  & Half  Yearly), Training Conduct, Training  Record  Preparation, Training  Feedback  Analysis, Evaluating  the Effectiveness  of training  programmers, Internal  Training Certificate  Preparation, Exposure  of DOJO  center  and development  of skill simulators, Independent  handling  DOJO  Training, Blue  Collar  Skill Development  (Skill gap  Analysis, On  Job Training  Plan, Skill  matrix  Upgradation), Independent  Handling  Audit  i.e. Internal  & IATF/ISO/EHS/VSA  etc., Candidate  sourcing  & screening, Arranging  interviews  with  HOD’s, Making LOI, Appointment letters , Confirmation Letter, Transfer letters , Salary Breakup, Negotiating salary with candidates, Taking care of all the joining formalities, Ensuring that all the documents of the new joiners are in accordance  with  the company’s policy, Preparation  of complete  job description, Explaining  KRAs  to all the new  joiners, New  Joiner  Employee  satisfaction  survey  on weekly/monthly/yearly  basis, Conducting Exit Interviews & Exit Formalities , Exit Analysis, Driving retention strategies to retain the talent  pool, Handling all Invoices  related  to HR, Keeping  Auditors  Requirements, Supporting  role in compliance  management, Recruitments Audits, Creating  master  data  of New  Joining  Staff in Savior Attendance Software or Time Office, Monthly  MIS Updating, KRA  Updating, R&R  and J.D Preparation, Organization  Chart  (O.C) prepared  & updated  on monthly basis, Meeting, Department  Review  meeting – MOM  Preparation  & follow -up & closing, Team  Building  & Funny  Saturday  Activity, Poster  Slogan Competition  on theme  month, Jhatpat Activities  for Associate, Birthday  Celebration, Annual  Day & Festival  Celebration, Medical  camp  / Blood  donation camp  / Adhar Card  correction  & Banking camp etc.\n",
      "Executive (Training &  Development) at Dhoot Transmission Pvt Ltd. (9 Months)\n",
      "Responsibilities: Screening  & short -listing  candidates  profile  as per defined  competencies, Taking care of all the joining formalities, Ensuring that all the documents of the new joiners are in accordance  with  the company’s policy, CV screening  from job  portals, Independent  handling  DOJO  Training, Designing  Training Calendar  as per TNI for the entire  division, Evaluating  the Effectiveness of  training  programmes, Maintain  documents for Audits  like IATF/ISO  etc, Maintain  the all record  related to training, Conducting  reviews &  providing feedback  on areas  of improvements, Prepared  weekly training plan of  existing  manpower, Practically  training  given  to new  employee  in Dojo, Service award,  Performance  Rewards, Birthday wishes,  Wedding wishes, Training PPT’s, Festivals special day celebrations, Annual Day Celebrations\n",
      "Certifications: N/A\n",
      "Languages: Hindi, English\n"
     ]
    }
   ],
   "source": [
    "if isinstance(resume_text, dict) and \"error\" in resume_text:\n",
    "    print(resume_text[\"error\"])\n",
    "else:\n",
    "    # Parse the resume text using the generative model\n",
    "    response = resumes_details(resume_text)\n",
    "\n",
    "    # Clean the response\n",
    "    response_clean = response.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "\n",
    "# Load the cleaned response into a dictionary\n",
    "try:\n",
    "    data = json.loads(response_clean)\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Failed to parse resume details\")\n",
    "    data = {}\n",
    "\n",
    "# Set default values for missing fields\n",
    "full_name = data.get(\"Full Name\", \"N/A\")\n",
    "contact_number = data.get(\"Contact Number\", \"N/A\")\n",
    "email_address = data.get(\"Email Address\", \"N/A\")\n",
    "location = data.get(\"Location\", \"N/A\")\n",
    "\n",
    "# Skills extraction\n",
    "skills = data.get(\"Skills\", {})\n",
    "technical_skills = skills.get(\"Technical Skills\", [])\n",
    "non_technical_skills = skills.get(\"Non-Technical Skills\", [])\n",
    "technical_skills_str = \", \".join(technical_skills) if technical_skills else \"N/A\"\n",
    "non_technical_skills_str = \", \".join(non_technical_skills) if non_technical_skills else \"N/A\"\n",
    "\n",
    "# Education extraction\n",
    "education_list = data.get(\"Education\", [])\n",
    "education_str = \"\\n\".join([\n",
    "    f\"{edu.get('Degree', 'N/A')} from {edu.get('Institution', 'N/A')} (Graduated: {edu.get('Years', 'N/A')})\"\n",
    "    for edu in education_list\n",
    "]) if education_list else \"N/A\"\n",
    "\n",
    "# Work Experience extraction\n",
    "work_experience_list = data.get(\"Work Experience\", [])\n",
    "work_experience_str = \"\\n\".join([\n",
    "    f\"{job.get('Job Title', 'N/A')} at {job.get('Company Name', 'N/A')} ({job.get('Years of Experience', 'N/A')})\\nResponsibilities: {', '.join(job.get('Responsibilities', []) if job.get('Responsibilities') else ['N/A'])}\"\n",
    "    for job in work_experience_list\n",
    "]) if work_experience_list else \"N/A\"\n",
    "\n",
    "# Certifications extraction\n",
    "certifications_str = \", \".join(data.get(\"Certifications\", [])) if data.get(\"Certifications\") else \"N/A\"\n",
    "\n",
    "# Languages extraction\n",
    "languages_str = \", \".join(data.get(\"Languages spoken\", [])) if data.get(\"Languages spoken\") else \"N/A\"\n",
    "\n",
    "# Print extracted details\n",
    "print(f\"Full Name: {full_name}\")\n",
    "print(f\"Contact Number: {contact_number}\")\n",
    "print(f\"Email Address: {email_address}\")\n",
    "print(f\"Location: {location}\")\n",
    "print(f\"Technical Skills: {technical_skills_str}\")\n",
    "print(f\"Non-Technical Skills: {non_technical_skills_str}\")\n",
    "print(f\"Education: {education_str}\")\n",
    "print(f\"Work Experience: {work_experience_str}\")\n",
    "print(f\"Certifications: {certifications_str}\")\n",
    "print(f\"Languages: {languages_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Json Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_details = {\n",
    "    \"Full Name\": full_name,\n",
    "    \"Contact Number\": contact_number,\n",
    "    \"Email Address\": email_address,\n",
    "    \"Location\": location,\n",
    "    \"Technical Skills\": technical_skills_str,\n",
    "    \"Non-Technical Skills\": non_technical_skills_str,\n",
    "    \"Education\": education_str,\n",
    "    \"Work Experience\": work_experience_str,\n",
    "    \"Certifications\": certifications_str,\n",
    "    \"Languages\": languages_str\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = re.sub(r'[^a-zA-Z0-9]', '_', full_name)  \n",
    "json_filename = f\"{name}.json\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume details successfully saved to Preeti.json\n"
     ]
    }
   ],
   "source": [
    "with open(json_filename, \"w\") as json_file:\n",
    "    json.dump(resume_details, json_file, indent=4)\n",
    "\n",
    "print(f\"Resume details successfully saved to {json_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (aftrai)",
   "language": "python",
   "name": "aftrai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
